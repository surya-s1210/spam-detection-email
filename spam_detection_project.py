# -*- coding: utf-8 -*-
"""Spam detection project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RuE4SKiJoFFHhIWkVj8eydVqOzTFBxZU
"""

import pandas as pd
import random
import uuid
import re
import string
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Download stopwords
nltk.download('stopwords')

# Load dataset
file_path = "/content/email_spam_dataset.csv"
df = pd.read_csv(file_path)

# Clean text function
def clean_text(text):
    if pd.isna(text):
        return ""
    text = text.lower()  # Convert to lowercase
    text = re.sub(f"[{re.escape(string.punctuation)}]", "", text)  # Remove punctuation
    text = " ".join([word for word in text.split() if word not in stopwords.words('english')])  # Remove stopwords
    return text

# Clean subject and body
df["clean_subject"] = df["subject"].apply(clean_text)
df["clean_body"] = df["body"].apply(clean_text)
df["text"] = df["clean_subject"] + " " + df["clean_body"]

# TF-IDF vectorization
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df["text"])
y = df["spam"]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model training
model = LogisticRegression()
model.fit(X_train, y_train)

# Predictions and evaluation
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Model training complete!")

# Email prediction function
def predict_email(subject, body):
    email_text = clean_text(subject) + " " + clean_text(body)
    email_vector = vectorizer.transform([email_text])
    prediction = model.predict(email_vector)[0]
    result = "Spam" if prediction == 1 else "Not Spam"
    print("\nEmail:")
    print("Subject:", subject)
    print("Body:", body)
    print("Prediction:", result)
    return result

# Sample prediction
sample_subject = "Win a free vacation now!"
sample_body = "Click the link to claim your reward today. Limited time offer!"
prediction_result = predict_email(sample_subject, sample_body)

# Load dataset
# Ensure the file path is correct. If the file is in a different location,
# update the file_path variable to the correct path.
file_path = "/content/email_spam_dataset.csv"
df = pd.read_csv(file_path)

import pandas as pd

# Sample data
data = {
    "subject": [
        "Win a free iPhone now!",
        "Meeting agenda for Monday",
        "Limited time offer just for you",
        "Your Amazon order has shipped",
        "Get rich quick with this trick",
        "Weekly project update",
    ],
    "body": [
        "Click here to claim your free iPhone. Offer ends soon.",
        "Please review the agenda and bring notes.",
        "Act fast! This deal won't last long. Click the link now.",
        "Your order #12345 has been shipped. Track it here.",
        "Make thousands working from home. Sign up now.",
        "Here is the progress report for this week.",
    ],
    "spam": [1, 0, 1, 0, 1, 0]  # 1 = spam, 0 = not spam
}

# Create DataFrame and save as CSV
df = pd.DataFrame(data)
df.to_csv("email_spam_dataset.csv", index=False)

print("Sample dataset created and saved as 'email_spam_dataset.csv'")

import pandas as pd
import random
import uuid
import re
import string
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Download stopwords
nltk.download('stopwords')

# Load dataset
file_path = "/content/email_spam_dataset.csv"
df = pd.read_csv(file_path)

# Clean text function
def clean_text(text):
    if pd.isna(text):
        return ""
    text = text.lower()  # Convert to lowercase
    text = re.sub(f"[{re.escape(string.punctuation)}]", "", text)  # Remove punctuation
    text = " ".join([word for word in text.split() if word not in stopwords.words('english')])  # Remove stopwords
    return text

# Clean subject and body
df["clean_subject"] = df["subject"].apply(clean_text)
df["clean_body"] = df["body"].apply(clean_text)
df["text"] = df["clean_subject"] + " " + df["clean_body"]

# TF-IDF vectorization
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df["text"])
y = df["spam"]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model training
model = LogisticRegression()
model.fit(X_train, y_train)

# Predictions and evaluation
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Model training complete!")

# Email prediction function
def predict_email(subject, body):
    email_text = clean_text(subject) + " " + clean_text(body)
    email_vector = vectorizer.transform([email_text])
    prediction = model.predict(email_vector)[0]
    result = "Spam" if prediction == 1 else "Not Spam"
    print("\nEmail:")
    print("Subject:", subject)
    print("Body:", body)
    print("Prediction:", result)
    return result

# Sample prediction
sample_subject = "Win a free vacation now!"
sample_body = "Click the link to claim your reward today. Limited time offer!"
prediction_result = predict_email(sample_subject, sample_body)